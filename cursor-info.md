# ğŸ“š QAHelper: Agente conversacional RAG con LangGraph, Gemini y Guardrails

## ğŸ§  DescripciÃ³n del Proyecto

Este sistema implementa un asistente conversacional basado en:
- RAG (Retrieval-Augmented Generation)
- LangGraph para modelar flujos de agentes
- LangChain como framework de orquestaciÃ³n
- Gemini como LLM principal
- Guardrails AI para moderar respuestas ofensivas o sensibles
- PostgreSQL para almacenar sesiones y mensajes

El objetivo es que un usuario realice preguntas y el sistema:
1. Elija dinÃ¡micamente quÃ© tool del servidor MCP usar.
2. Ejecute esa tool (por ejemplo, bÃºsqueda de documentos o FAQs).
3. Genere una respuesta final utilizando el resultado anterior como contexto.
4. Pase la respuesta por un guardrail para moderaciÃ³n (si aplica).
5. Almacene el mensaje final si fue modificado.

## ğŸ“ Estructura principal
backend/
â”‚
â”œâ”€â”€ agents/
â”‚ â””â”€â”€ rag_agent.py â†’ Define el agente RAG con MCP, Gemini y moderaciÃ³n
â”‚
â”œâ”€â”€ graph/
â”‚ â””â”€â”€ graph_builder.py â†’ Crea el grafo LangGraph y los nodos asociados
â”‚
â”œâ”€â”€ moderation/
â”‚ â””â”€â”€ guardrail.py â†’ Implementa filtros de contenido ofensivo y reescribe mensajes con Gemini si es necesario
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ db.py â†’ ORM con SQLAlchemy para sessions, messages, embeddings
â”‚
â””â”€â”€ utils/
â””â”€â”€ db_connection.py â†’ ConexiÃ³n a PostgreSQL

## ğŸ—ƒï¸ Base de datos (PostgreSQL en AWS)

- `chat_sessions`: Sesiones activas
- `chat_messages`: Historial de mensajes con `role` y `message`
- `document_embeddings`: Chunks de documentos vectorizados

## âš™ï¸ TecnologÃ­as y herramientas clave

- **LangGraph**: para flujo de control entre nodos
- **LangChain**: agentes, memoria, tools
- **Gemini API**: LLM principal
- **Guardrails-AI**: moderaciÃ³n y validaciÃ³n
- **FastMCP**: servidor que expone tools como endpoints
- **PostgreSQL**: persistencia de sesiones/mensajes
- **Streamlit**: interfaz del usuario (frontend liviano)

## ğŸ›‘ Reglas y convenciones

- Las variables de entorno se cargan desde `.env` y no deben ser indexadas
- No exponer claves sensibles ni logs con texto generado
- Las respuestas moderadas se almacenan; si no hay alteraciÃ³n, se omite
- Se evita el hardcodeo de tools; todas se obtienen dinÃ¡micamente desde MCP
